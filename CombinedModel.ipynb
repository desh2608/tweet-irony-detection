{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import shuffle\n",
    "from string import punctuation\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, Activation\n",
    "from keras.models import Model,Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, optimizers\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble  import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    data_dict = {}\n",
    "    with open(filename) as f:\n",
    "        d = np.load(f)\n",
    "        data_dict[\"indices\"] = d['arr_0']\n",
    "        data_dict[\"X_train\"] = d['arr_1']\n",
    "        data_dict[\"X_test\"] = d['arr_2']\n",
    "        data_dict[\"y_train\"] = d['arr_3']\n",
    "        data_dict[\"y_test\"] = d['arr_4']\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[-1],),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        super(AttLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.tanh(K.dot(x, self.W))\n",
    "        \n",
    "        ai = K.exp(eij)\n",
    "        weights = ai/K.sum(ai, axis=1).dimshuffle(0,'x')\n",
    "        \n",
    "        weighted_input = x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "model_sarc = load_model(\"trainedmodels/sarc_transfer_all.h5\", custom_objects={'AttLayer':AttLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data[\"char_tfidf\"] = get_data('./trainedmodels/char_ngrams_tfidf.npz')\n",
    "data[\"holographic\"] = get_data('./trainedmodels/holographic.npz')\n",
    "data[\"sarc\"] = get_data('./trainedmodels/sarc_transfer_all.npz')\n",
    "data[\"deepmoji\"] = get_data('./trainedmodels/deepmoji.npz')\n",
    "data[\"sent\"] = get_data('./trainedmodels/sent_features.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sarc_features(x_text, labels):\n",
    "    embedding_weights = model_sarc.layers[0].get_weights()[0]\n",
    "    embed_size = embedding_weights.shape[1]\n",
    "    X, y = [], []\n",
    "    for i in range(len(x_text)):\n",
    "        emb = np.zeros(embed_size)\n",
    "        for word in x_text[i]:\n",
    "            try:\n",
    "                emb += embedding_weights[word]\n",
    "            except:\n",
    "                print \"Here\"\n",
    "                pass\n",
    "        emb /= len(x_text[i])\n",
    "        X.append(emb)\n",
    "        y.append(labels[i])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name ==\"xgb\":\n",
    "        return xgb.XGBClassifier()\n",
    "    elif model_name == \"lr\":\n",
    "        return LogisticRegression(class_weight=\"balanced\")\n",
    "    elif model_name == \"random_forest\":\n",
    "        return RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif model_name == \"svm\":\n",
    "        return LinearSVC(class_weight=\"balanced\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(name):\n",
    "    \n",
    "    if name in data:\n",
    "        data_dict = data[name]\n",
    "        X_train = data_dict[\"X_train\"]\n",
    "        Y_train = data_dict[\"y_train\"]\n",
    "        X_test = data_dict[\"X_test\"]\n",
    "        Y_test = data_dict[\"y_test\"]\n",
    "        return X_train, Y_train, X_test, Y_test\n",
    "    else:\n",
    "        print \"No data found\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, testX, testY):   \n",
    "    y_pred = model.predict(testX)\n",
    "    y_true = testY\n",
    "    precision = metrics.precision_score(y_true, y_pred, average=None)\n",
    "    recall = metrics.recall_score(y_true, y_pred, average=None)\n",
    "    f1_score = metrics.f1_score(y_true, y_pred, average=None)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    print(\"Precision: \" + str(precision) + \"\\n\")\n",
    "    print(\"Recall: \" + str(recall) + \"\\n\")\n",
    "    print(\"f1_score: \" + str(f1_score) + \"\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\":: Classification Report\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Accuracy: \" + str(accuracy) + \"\\n\")\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stack_features(name_1, name_2):\n",
    "    X_train = np.hstack((data[name_1][\"X_train\"], data[name_2][\"X_train\"]))\n",
    "    Y_train = data[name_1][\"y_train\"]\n",
    "    X_test = np.hstack((data[name_1][\"X_test\"], data[name_2][\"X_test\"]))\n",
    "    Y_test = data[name_1][\"y_test\"]\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_features(\"deepmoji\")\n",
    "model1 = get_model(\"xgb\")\n",
    "model1.fit(X_train, Y_train)\n",
    "y_pred1 = evaluate_model(model1, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_features(\"char_tfidf\")\n",
    "model2 = get_model(\"xgb\")\n",
    "model2.fit(X_train, Y_train)\n",
    "y_pred2 = evaluate_model(model2, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_features(\"holographic\")\n",
    "model3 = get_model(\"xgb\")\n",
    "model3.fit(X_train, Y_train)\n",
    "y_pred3 = evaluate_model(model3, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [0]*len(y_pred1)\n",
    "for i in range(len(y_pred1)):\n",
    "    if((y_pred1[i]=='1' and y_pred2[i]=='1') or (y_pred2[i]=='1' and y_pred3[i]=='1') or (y_pred2[i]=='1' and y_pred3[i]=='1')):\n",
    "        y_pred[i]=1\n",
    "\n",
    "y_true = Y_test.astype(int)\n",
    "precision = metrics.precision_score(y_true, y_pred, average=None)\n",
    "recall = metrics.recall_score(y_true, y_pred, average=None)\n",
    "f1_score = metrics.f1_score(y_true, y_pred, average=None)\n",
    "accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "print(\"Precision: \" + str(precision) + \"\\n\")\n",
    "print(\"Recall: \" + str(recall) + \"\\n\")\n",
    "print(\"f1_score: \" + str(f1_score) + \"\\n\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\":: Classification Report\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Accuracy: \" + str(accuracy) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = stack_features(\"holographic\",\"deepmoji\")\n",
    "model = get_model(\"xgb\")\n",
    "model.fit(X_train, Y_train)\n",
    "evaluate_model(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
